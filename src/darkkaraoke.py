#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""tom_da_musica.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xUIpnNGGsIY6qyTegYEs8UYxn8-_uHYc
"""

import os, json, yt_dlp, librosa, subprocess, random, textwrap, requests, difflib, shutil, codecs, pysrt, re, argparse, platform
import soundfile as sf
from pydub import AudioSegment
from moviepy.editor import *
import numpy as np
from PIL import Image, ImageDraw, ImageOps
from moviepy.video.tools.subtitles import SubtitlesClip
import librosa.display

try:
    from openai import OpenAI
    openai_api = 1
except Exception as e:
    print(f"Biblioteca OpenAI indisponível. Erro: {e}")
    openai_api = None

if platform.system() == "Windows":
    AudioSegment.converter = 'C:\\Users\\kazzt\\AppData\\Local\\Microsoft\\WinGet\\Packages\\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\\ffmpeg-7.0.2-full_build\\bin'
    from moviepy.config import change_settings
    change_settings({"IMAGEMAGICK_BINARY": r"C:\\Program Files\\ImageMagick-7.1.1-Q16-HDRI\\magick.exe"})
    print("Sistema operacional é Windows. Variáveis atribuídas.")
else:
    print("Sistema operacional não é Windows. Nenhuma ação realizada.")

def carregar_credenciais():
    with open('config/credentials.json') as f:
        return json.load(f)

credenciais = carregar_credenciais()
OPENAI_KEY = credenciais["OPENAI_API_KEY"]
UNSPLASH_KEY = credenciais["UNSPLASH_API_KEY"]

def baixar_imagens_paisagens(quantidade, tamanho='full_hd'):
    # Defina o tamanho da imagem com base na entrada
    resolucoes = {
        'full_hd': '1920x1080',
        '4k': '3840x2160',
        'vertical': '1080x1920',
        '480p': '854x480',
        'oldtv': '640x480'
    }

    if tamanho not in resolucoes:
        raise ValueError("Tamanho inválido. Escolha entre 'full_hd', '4k', 'vertical', '480p' ou 'oldtv'.")

    # Defina a URL da API do Unsplash
    url_base = "https://api.unsplash.com/photos/random"

    # Parâmetros da requisição
    params = {
        'query': 'landscape',
        'count': quantidade,
        'orientation': 'landscape',
        'client_id': UNSPLASH_KEY,
    }

    # Faça a requisição à API do Unsplash
    response = requests.get(url_base, params=params)
    if response.status_code != 200:
        raise Exception(f"Erro na requisição: {response.status_code}")

    # Crie um diretório para salvar as imagens
    diretorio_tamanho = f'imagens/{tamanho}'
    os.makedirs(diretorio_tamanho, exist_ok=True)

    # Descubra quantas imagens já existem na pasta
    contador_inicial = len([nome for nome in os.listdir(diretorio_tamanho) if os.path.isfile(os.path.join(diretorio_tamanho, nome))])

    # Baixe as imagens
    for i, foto in enumerate(response.json(), start=contador_inicial + 1):
        url_imagem = foto['urls']['raw'] + f"&fit=crop&w={resolucoes[tamanho].split('x')[0]}&h={resolucoes[tamanho].split('x')[1]}"
        response_img = requests.get(url_imagem)
        if response_img.status_code == 200:
            caminho_imagem = os.path.join(diretorio_tamanho, f'paisagem_{i:02d}.jpg')
            with open(caminho_imagem, 'wb') as f:
                f.write(response_img.content)
            print(f'Imagem {i} baixada com sucesso.')
        else:
            print(f'Falha ao baixar a imagem {i}.')

def transcribe_audio_whisper(audio_file, language='en', model='small', porpalavra=True, limpalavras=8):
  """
  Transcribes an audio file using OpenAI Whisper via command line.

  Args:
    audio_file: Path to the audio file.
  """
  print(f"Transcrevendo arquivo {audio_file} usando o idioma {language} e modelo {model}. Aguarde...")
  command = f"whisper {audio_file} --model {model} --language {language} --output_format srt --word_timestamps {porpalavra} --max_words_per_line {limpalavras}"

  process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  output, error = process.communicate()

  if error:
    print(f"Error: {error.decode()}")
  else:
    print(f"Output: {output.decode()}")

def transcribe_audio_whisper_api(audio_file, output_file, language='en'):
    if openai_api: 
        print('Transcrevendo gravação via OpenAI API')
        client = OpenAI(api_key=OPENAI_KEY)
        
        # Verifica se o arquivo é WAV e converte para MP3 se necessário
        if audio_file.lower().endswith('.wav'):
            audio = AudioSegment.from_wav(audio_file)
            audio_file_mp3 = audio_file.replace('.wav', '.mp3')
            audio.export(audio_file_mp3, format='mp3')
            audio_file = audio_file_mp3
        
        # Verifica o tamanho do arquivo
        if os.path.getsize(audio_file) > 25 * 1024 * 1024:
            raise ValueError("O arquivo de áudio excede o limite de 25 MB.")
        
        with open(audio_file, 'rb') as f:
            response = client.audio.transcriptions.create(
                file=f,
                model='whisper-1',
                language=language,
                response_format='srt'
            )
        
        #print(response)
        
        with open(output_file, 'w') as f:
            f.write(response)
        
        print(f'Transcrição salva em {output_file}')
        return output_file
    else:
        print('OpenAI API indisponível. Não foi possível criar legenda por esse método.')
        return None

def separar_audio_demucs(audio_file, stems=None):
  """
  Separa o áudio em stems usando o Demucs.

  Args:
    audio_file: Caminho para o arquivo de áudio.
  """
  print(f"Separando o áudio {audio_file} em stems com Demucs...")
  if stems:
    command = f"demucs -n htdemucs --two-stems=vocals {audio_file} -o separated_audio --filename temp_audio/{{stem}}.{{ext}}"
  else:
    command = f"demucs -n htdemucs_ft  {audio_file} -o separated_audio --filename {{stem}}.{{ext}}"
  process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  output, error = process.communicate()

  if error:
    print(f"Error: {error.decode()}")
  else:
    print(f"Output: {output.decode()}")
    print("Áudio separado em stems com sucesso!")
  return "separated_audio/htdemucs_ft"

def separate_audio_spleeter(audio_file, stems=4):
  """
  Separates audio using Spleeter via subprocess.

  Args:
    audio_file: Path to the audio file.
  """
  validstems = [2, 4, 5]
  if stems not in validstems:
    raise ValueError(f"Quantidade de vozes inválida. Precisa ser entre {validstems}.")
  else:
    print(f"Separando arquivo {audio_file} em {stems} stems.")
    command = f"spleeter separate {audio_file} -p spleeter:{stems}stems -o separated_audio"
    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    output, error = process.communicate()
    if error:
      print(f"Error: {error.decode()}")
    else:
      print(f"Output: {output.decode()}")
  return "separated_audio/temp_audio"

def buscar_letra_lyrics_ovh(titulo, artista):
    """
    Busca a letra de uma música usando a API do Lyrics.ovh.

    :param titulo: Título da música.
    :param artista: Nome do artista.
    :return: Letra da música ou None se não for encontrada.
    """
    base_url = f"https://api.lyrics.ovh/v1/{artista}/{titulo}"
    response = requests.get(base_url)

    if response.status_code == 200:
        return response.json().get('lyrics', '').strip()
    return None

def corrigir_legenda_srt_com_letra(srt_file, titulo_musica, artista):
    """
    Compara e corrige a letra de um arquivo SRT com a letra encontrada na base de dados Lyrics.ovh.

    :param srt_file: Caminho para o arquivo SRT a ser corrigido.
    :param titulo_musica: Título da música.
    :param artista: Nome do artista.
    :return: Conteúdo corrigido do arquivo SRT ou uma mensagem se a letra não for encontrada.
    """
    letra_corrigida = buscar_letra_lyrics_ovh(titulo_musica, artista)

    if not letra_corrigida:
        return "Letra não encontrada na base de dados Lyrics.ovh."

    with open(srt_file, 'r', encoding='utf-8') as file:
        srt_content = file.readlines()

    # Separar a letra corrigida em linhas
    lyrics_lines = letra_corrigida.splitlines()

    # Inicializar o índice para a letra corrigida
    lyric_index = 0
    corrected_srt_content = []

    for line in srt_content:
        if not line.strip().isdigit() and '-->' not in line:
            if lyric_index < len(lyrics_lines):
                # Substituir a linha da legenda pela linha correspondente da letra corrigida
                corrected_line = lyrics_lines[lyric_index]
                corrected_srt_content.append(corrected_line + '\n')
                lyric_index += 1
            else:
                # Se a letra corrigida tiver menos linhas que o SRT, manter a linha original
                corrected_srt_content.append(line)
        else:
            corrected_srt_content.append(line)

    # Nome do arquivo de saída baseado no artista e título da música
    nome_arquivo = f"{artista.replace(' ', '_')}_{titulo_musica.replace(' ', '_')}.srt"
    corrected_filename = os.path.join(os.path.dirname(srt_file), nome_arquivo)

    # Salvar o arquivo SRT corrigido
    with open(corrected_filename, 'w', encoding='utf-8') as corrected_file:
        corrected_file.writelines(corrected_srt_content)

    return corrected_filename

def avaliar_url_ou_arquivo(string):
  """
  Avalia se uma string é uma URL ou um endereço de arquivo local.

  Args:
    string: A string a ser avaliada.

  Returns:
    'url' se a string for uma URL, 'arquivo' se for um endereço de arquivo local,
    ou 'desconhecido' se não puder ser determinado.
  """
  if re.match(r'^(https?|ftp)://', string):
    return 'url'
  elif re.match(r'^[a-zA-Z0-9_\-\s\/\.]+$', string):
    return 'arquivo'
  else:
    return 'desconhecido'

def replace_lyrics_in_srt(srt_file, artist, title):
    """
    Substitui o texto das legendas em um arquivo SRT pelos versos da música encontrada em lyrics.ovh.
    
    Args:
        srt_file: Caminho para o arquivo SRT existente.
        artist: Nome do artista.
        title: Título da música.
    
    Returns:
        O caminho para o arquivo SRT atualizado ou None se a letra não for encontrada.
    """
    # Busca a letra da música
    lyrics = buscar_letra_lyrics_ovh(artist, title)
    
    if lyrics is None:
        print("Letra não encontrada.")
        return None
    
    # Divide a letra em linhas
    lyrics_lines = [line for line in lyrics.split('\n') if line.strip()]

    # Verifica se o arquivo SRT existe
    if not os.path.exists(srt_file):
        print(f"Arquivo SRT não encontrado: {srt_file}")
        return None

    # Lê o arquivo SRT existente
    subs = pysrt.read(srt_file, encoding='utf-8')

    # Verifica se o número de legendas corresponde ao número de linhas da letra
    if len(subs) != len(lyrics_lines):
        print(f"Número de legendas ({len(subs)}) não corresponde ao número de versos ({len(lyrics_lines)})")
        return None

    # Substitui o texto das legendas
    for i, line in enumerate(lyrics_lines):
        subs[i].text = line

    # Cria o nome do arquivo de saída
    base, ext = os.path.splitext(srt_file)
    output_filename = f"{base}_updated{srt_file}"

    # Salva o arquivo SRT atualizado
    subs.save(output_filename, encoding='utf-8')
    
    return output_filename

def baixar_legenda(url_video, idioma=None, formato='srt', saida_arquivo=None):
    """
    Baixa a legenda de um vídeo do YouTube em formato SRT.
    Pode-se especificar o idioma desejado ou usar o idioma principal detectado do vídeo.
    """
    ydl_opts = {
        'skip_download': True,
        'writesubtitles': True,
        'subtitlesformat': formato,
        'outtmpl': saida_arquivo if saida_arquivo else '%(title)s.%(ext)s'
    }

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info_dict = ydl.extract_info(url_video, download=False)
        idioma_video = idioma if idioma else info_dict.get('language', None)

        if 'subtitles' in info_dict and idioma_video in info_dict['subtitles']:
            ydl_opts['subtitleslangs'] = [idioma_video]
            ydl.download([url_video])
            titulo = info_dict.get('title', None)
            nome_arquivo_legenda = f"{titulo}.{idioma_video}.{formato}" if saida_arquivo is None else saida_arquivo
            return f"Legenda baixada: {nome_arquivo_legenda}"
        else:
            return f"Nenhuma legenda disponível no idioma {'especificado' if idioma else 'detectado'} ({idioma_video})."

def convert_audio_to_wav(input_file, output_file):
    """
    Converte um arquivo de áudio para o formato WAV usando imageio-ffmpeg.

    Args:
        input_file: Caminho para o arquivo de áudio de entrada.
        output_file: Caminho para o arquivo WAV de saída.
    """
    command = [
        'ffmpeg', '-y',  # Adiciona o parâmetro -y para sobrescrever o arquivo de saída
        '-i', input_file,
        '-ar', '44100',  # Taxa de amostragem de 44100 Hz
        '-ac', '2',      # Estéreo
        '-f', 'wav',
        output_file
    ]

    try:
        subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    except subprocess.CalledProcessError as e:
        print(f"Erro ao converter o áudio: {e.stderr}")
        raise

def sync_lyrics_with_audio(artist, title, audio_file):
    """
    Sincroniza as letras com o áudio detectando intervalos de som e silêncio.

    Args:
        artist: Nome do artista.
        title: Título da música.
        audio_file: Caminho para o arquivo de áudio (vocals.wav).

    Returns:
        Nome do arquivo SRT gerado ou None se a letra não foi encontrada.
    """
    # Busca as letras da música
    lyrics = buscar_letra_lyrics_ovh(artist, title)

    if lyrics is None:
        print("Letra não encontrada.")
        return None

    # Converte o áudio para o formato WAV se necessário
    temp_audio_file = 'temp_audio.wav'
    convert_audio_to_wav(audio_file, temp_audio_file)

    # Carrega o áudio
    y, sr = librosa.load(temp_audio_file, sr=44100)

    # Calcula a energia do sinal em janelas de 2048 samples (ou seja, cada passo corresponde a 2048/sr segundos)
    frame_length = 2048
    hop_length = 512
    energy = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]

    # Detecta intervalos onde a energia está acima de um certo limiar (ou seja, onde há som)
    threshold = 0.01
    sound_indices = np.where(energy > threshold)[0]

    # Calcula os tempos baseados nos índices
    sound_times = librosa.frames_to_time(sound_indices, sr=sr, hop_length=hop_length)

    # Divide a letra em linhas
    lyrics_lines = lyrics.split('\n')

    # Ajusta a quantidade de versos para o número de intervalos de som detectados
    if len(sound_times) > len(lyrics_lines):
        sound_times = sound_times[:len(lyrics_lines)]

    # Cria as entradas do arquivo SRT usando pysrt
    subs = pysrt.SubRipFile()
    for i in range(len(sound_times) - 1):
        start_time = sound_times[i]
        end_time = sound_times[i + 1]

        # Convertendo os tempos para o formato SRT
        start_ms = int(start_time * 1000)
        end_ms = int(end_time * 1000)

        # Criação do objeto Subtitle para cada linha de texto
        subs.append(pysrt.SubRipItem(index=i + 1,
                                     start=pysrt.SubRipTime(milliseconds=start_ms),
                                     end=pysrt.SubRipTime(milliseconds=end_ms),
                                     text=lyrics_lines[i]))

    # Criação do nome do arquivo de saída
    output_filename = os.path.join('sub', f"{artist}_{title}.srt")

    # Cria a pasta 'sub' se não existir
    os.makedirs(os.path.dirname(output_filename), exist_ok=True)

    # Salva o arquivo SRT
    subs.save(output_filename, encoding='utf-8')

    # Remove o arquivo temporário
    os.remove(temp_audio_file)

    return output_filename

def run_ultrasinger(input_file, output_folder):
  """
  Executa o comando "py src\\UltraSinger.py -i (arquivo ou url) -o (pasta de saída)"

  Args:
    input_file: Caminho para o arquivo de áudio ou URL.
    output_folder: Pasta de saída para os resultados.
  """
  print(f"Executando UltraSinger com entrada {input_file} e saída {output_folder}...")
  command = f"python3.10 UltraSinger/src/UltraSinger.py -i \"{input_file}\" -o {output_folder} --force_cpu True"
  process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  output, error = process.communicate()

  if error:
    print(f"Error: {error.decode()}")
  else:
    print(f"Output: {output.decode()}")
    print("UltraSinger executado com sucesso!")

def baixar_audio_mp3(url_video, nome_arquivo=None):
  """
  Baixa o áudio de um vídeo do YouTube no formato MP3 usando yt-dlp.

  Args:
    url_video: URL do vídeo do YouTube.
    nome_arquivo: Nome do arquivo de saída (opcional).
  """

  ydl_opts = {'extract_audio': True,
                         'format': 'bestaudio',
                         'outtmpl': os.path.join('audio', nome_arquivo) if nome_arquivo else os.path.join('audio', '%(title)s.%(ext)s'),
                         'postprocessors': [{  # Extract audio using ffmpeg
                                             'key': 'FFmpegExtractAudio',
                                               'preferredcodec': 'mp3',
                                               'preferredquality': '340',
                                               }]
                         }

  with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download([url_video])
    return f'{ydl.prepare_filename(ydl.extract_info(url_video, download=False))}.mp3'

def create_playback(entrada, pitch_shift=None, separador='spleeter', legenda='nenhum', idioma_legenda=None, artista=None, musica=None, modelowhisper=None, stems=4, whisper_palavra=True, whisper_limpalavras=8):
    """
    Downloads a video or audio from a URL, separates instruments, removes vocals,
    changes pitch (optional), and mixes the remaining instruments back together.

    Args:
        url: URL of the video or audio.
        pitch_shift: Number of steps to shift the pitch (positive for up, negative for down).
        legenda_func: Método para obter legendas ('whisper' ou 'yt_dlp').
        idioma_legenda: Idioma das legendas a serem baixadas (se aplicável).
    """
    arquivo_tmp = 'temp_audio.mp3'
    arquivo_nome = ''
    if avaliar_url_ou_arquivo(entrada) == 'url': 
        # Download audio using yt-dlp
        print('Baixando áudio usando yt-dlp')
        arquivo_forma = f'baixado/{artista} - {musica} (original)'
        arquivo_nome = baixar_audio_mp3(entrada, arquivo_forma)
        print(arquivo_nome)
        shutil.copyfile(arquivo_nome, arquivo_tmp)
    else:
        try:
            shutil.copyfile(entrada, arquivo_tmp)
            arquivo_nome = os.path.basename(entrada)
        except:
            print('Arquivo de entrada inválido')
    dir_stems = ""
    # Separate audio using spleeter
    print('Separando instrumentos')
    if separador == 'demucs':
      dir_stems = separar_audio_demucs(arquivo_tmp)
    else:
      if stems:
        dir_stems = separate_audio_spleeter(arquivo_tmp, stems=stems)
      else:
        dir_stems = separate_audio_spleeter(arquivo_tmp)

    # Remove vocals and obtain subtitles
    arq_legenda = None
    if legenda == 'whisper':
      print('Obtendo legenda via openai-whisper')
      arq_legenda = f'sub/{artista} - {musica}.srt'
      if idioma_legenda:
        if modelowhisper:
          transcribe_audio_whisper(f'{dir_stems}/vocals.wav', language=idioma_legenda, model=modelowhisper, porpalavra=whisper_palavra, limpalavras=whisper_limpalavras)
        else:
          transcribe_audio_whisper(f'{dir_stems}/vocals.wav', language=idioma_legenda, porpalavra=whisper_palavra, limpalavras=whisper_limpalavras)
      else:
        if modelowhisper:
          transcribe_audio_whisper(f'{dir_stems}/vocals.wav', model=modelowhisper, porpalavra=whisper_palavra, limpalavras=whisper_limpalavras)
        else:
          transcribe_audio_whisper(f'{dir_stems}/vocals.wav', porpalavra=whisper_palavra, limpalavras=whisper_limpalavras)
      os.rename('vocals.srt', arq_legenda)
    elif legenda == 'yt_dlp':
      print('Obtendo legenda via yt-dlp (se disponível)')
      arq_legenda = f'sub/{arquivo_nome}.srt'
      baixar_legenda(entrada, idioma=idioma_legenda, formato='srt', saida_arquivo=arq_legenda)
    elif legenda == 'lyrics_ovh':
      print('Obtendo legenda via lyrics.ovh (se disponível)')
      if artista and musica:
        arq_legenda = sync_lyrics_with_audio(artista, musica, f'{dir_stems}/vocals.wav')
      else:
        print('Letra da música não encontrados na base de dados lyrics.ovh.')
        arq_legenda = None
    elif legenda == 'whisper-api':
        print('Obtendo legenda via api openai-whisper')
        arq_legenda = f'sub/{artista} - {musica}.srt'
        arq_legenda = transcribe_audio_whisper_api(f'{dir_stems}/vocals.wav', arq_legenda, language=idioma_legenda)
    else:
      arq_legenda = None
      print('Processamento sem legenda.')

    playbackinstruments = []
    # Change pitch of instruments (except drums) if pitch_shift is provided
    print('Alterando tom')
    if pitch_shift:
        if stems == 2:
            print('Não é possível alterar tom de um som com bateria incorporada.')
        else:
            if stems == 4:
              playbackinstruments = ['bass', 'other']
            elif stems == 5:
              playbackinstruments = ['bass', 'other', 'piano']
        for instrument in playbackinstruments:
            audio_stems = f'{dir_stems}/{instrument}.wav'
            if os.path.exists(audio_stems):
                change_pitch(audio_stems, pitch_shift)
            else:
                print(f"Arquivo {audio_stems} não encontrado, pulando a alteração de tom.")
        else:
          print('Sem alteração de tom.')

    # Mix remaining instruments back together
    print('Mesclando instrumentos')
    arqfinal = ""
    if artista and musica:
        arqfinal = mix_audio(arquivo_nome, pitch_shift, dir_stems, stems=stems, artist=artista, song=musica)
    else:
        arqfinal = mix_audio(arquivo_nome, pitch_shift, dir_stems, stems=stems)

    # Remove temporary files
    print('Removendo arquivos temporários')
    shutil.rmtree('separated_audio')
    os.remove(arquivo_tmp)

    return arqfinal, arq_legenda, pitch_shift, artista, musica

def mix_audio(filename, pitch_shift, dir_stems, stems=4, artist=None, song=None):
  """
  Mixes audio files back together and saves as mp3.

  Args:
    filename: Name of the audio file (without extension).
    pitch_shift: Pitch shift value used (if any) for naming the output file.
  """
  playbackinstruments = []
  if stems == 2:
    playbackinstruments = ['accompaniment']
  elif stems == 4:
    playbackinstruments = ['bass', 'other', 'drums']
  elif stems == 5:
    playbackinstruments = ['bass', 'other', 'piano', 'drums']

  audio_files = [f'{dir_stems}/{instrument}.wav' for instrument in playbackinstruments]

  combined = AudioSegment.empty()
  for file in audio_files:
    if os.path.exists(file):
      sound = AudioSegment.from_wav(file)
      if len(combined) == 0:
        combined = sound
      else:
        combined = combined.overlay(sound)
  if artist and song:
      if pitch_shift:
          output_filename = f'audio/{artist} - {song} (playback transposed {pitch_shift}).mp3'
      else:
          output_filename = f'audio/{artist} - {song}.mp3'
  else:
      if pitch_shift:
          output_filename = f'audio/{filename}_playback_{pitch_shift}.mp3'
      else:
          output_filename = f'audio/{filename}_playback.mp3'

  combined.export(output_filename, format="mp3")
  return output_filename

def change_pitch(audio_file, steps): # Added the missing change_pitch function
  """
  Changes the pitch of an audio file.

  Args:
    audio_file: Path to the audio file.
    steps: Number of steps to shift the pitch.
  """
  y, sr = librosa.load(audio_file)
  y_shifted = librosa.effects.pitch_shift(y, sr=sr, n_steps=steps)
  sf.write(audio_file, y_shifted, sr)
  print(f"Tom do arquivo {audio_file} alterado em {steps} semitons.")

def load_subtitles_with_encoding(subtitle_file, encoding='utf-8'):
    if not os.path.exists(subtitle_file) or os.path.getsize(subtitle_file) == 0:
        return None
    with codecs.open(subtitle_file, 'r', encoding=encoding) as file:
        return file.read()

def interpolate_color(start_color, end_color, alpha):
    return tuple(int(s * (1 - alpha) + e * alpha) for s, e in zip(start_color, end_color))

def rgb_to_hex(color_tuple):
    return '#{:02x}{:02x}{:02x}'.format(*color_tuple)

def create_karaoke_video(audio_file, subtitle_file, output_file, artist=None, song=None, key_shift=None, resolution='1080p', image_folder=None):
    size = (800, 600)
    if resolution == '4k':
        size = (3840, 2160)
        font_size_title_large = 36
        font_size_title_medium = 18
        font_size_subtitle = 180
    elif resolution == 'vertical':
        size = (1080, 1920)
        font_size_title_large = 28
        font_size_title_medium = 14
        font_size_subtitle = 120
    elif resolution == '480p':
        size = (854, 480)
        font_size_title_large = 14
        font_size_title_medium = 7
        font_size_subtitle = 60
    elif resolution == 'oldtv':
        size = (640, 480)
        font_size_title_large = 14
        font_size_title_medium = 7
        font_size_subtitle = 60
    else:
        size = (1920, 1080)
        font_size_title_large = 32
        font_size_title_medium = 16
        font_size_subtitle = 120
    
    subtitle_position = ('center', int(size[1] // 3))
        
    font_impact = 'ttf/IMPACT.TTF'
    font_arial = 'ttf/ARIAL.TTF'
    font_cooperblack = 'ttf/COOPBL.TTF'

    audio, sr = librosa.load(audio_file, sr=None)
    S = np.abs(librosa.stft(audio))
    S_db = librosa.amplitude_to_db(S, ref=np.max)
    audio_duration = librosa.get_duration(y=audio, sr=sr)
    fps = 24

    if image_folder:
        images = []
        for img_file in os.listdir(image_folder):
            img_path = os.path.join(image_folder, img_file)
            img = Image.open(img_path)
            if key_shift is None or key_shift == 0:
                img = img.convert('RGBA')  # Manter a cor original, mas aplicar suavização
                img = Image.blend(img, Image.new('RGBA', img.size, (255, 255, 255, 128)), alpha=0.3)
            else:
                img = ImageOps.grayscale(img).convert('RGBA')  # Convertendo para tons de cinza
            img = img.resize(size)
            images.append(img)
        random.shuffle(images)
        max_images = int(min(len(images), audio_duration // 10))
        images = images[:max_images]

    def make_frame(t):
        frame_index = int(t * sr / (len(S_db[0]) / audio_duration))
        if frame_index < len(S_db[0]):
            spec_slice = S_db[:, frame_index]
        else:
            spec_slice = np.zeros(S_db.shape[0])

        spec_line = (spec_slice + 80).astype(np.uint8)
        spec_image = np.stack([spec_line]*10, axis=1)

        spec_image = np.repeat(spec_image[:, :, np.newaxis], 3, axis=2)
        spec_image = Image.fromarray(spec_image).resize(size).convert('RGBA')
        alpha_channel = Image.new('L', spec_image.size, color=100)
        spec_image.putalpha(alpha_channel)

        if image_folder and images:
            img_index = int(t // (audio_duration / len(images)))
            background = images[img_index].convert('RGBA')
        else:
            # Definir fundo azul-marinho quando não houver imagens fornecidas
            if key_shift is None or key_shift == 0:
                background = Image.new('RGBA', size, color=(0, 0, 128, 255))  # Azul-marinho para key_shift None ou 0
            else:
                background = Image.new('RGBA', size, color=(10, 10, 10, 255))  # Cinza escuro padrão

        background.paste(spec_image, (0, (size[1] - spec_image.size[1]) // 2), spec_image)

        return np.array(background.convert('RGB'))

    spectrogram_clip = VideoClip(make_frame, duration=audio_duration)

    subtitle_text = load_subtitles_with_encoding(subtitle_file, encoding='utf-8')

    def create_subtitle_clip(txt, duration):
        if not txt:
            return ImageClip("imagens/1pixel.png").set_duration(duration)

        def color_transition(t):
            # Calcula a porcentagem do tempo decorrido
            progress = min(1, max(0, t / duration))

            # Usa a largura de 80% da tela
            wrapped_text = textwrap.fill(txt, width=50)

            # Cria o clipe de texto branco com transparência
            text_clip_white = TextClip(wrapped_text, fontsize=font_size_subtitle, color='white', 
                                       font=font_impact, stroke_color='black', stroke_width=2, 
                                       method='caption', align='center', size=(int(size[0] * 0.8), None), 
                                       transparent=True)

            # Cria o clipe de texto amarelo
            text_clip_yellow = TextClip(wrapped_text, fontsize=font_size_subtitle, color='yellow', 
                                        font=font_impact, stroke_color='black', stroke_width=2, 
                                        method='caption', align='center', size=(int(size[0] * 0.8), None))

            # Cria a máscara para o efeito de revelação de cor amarela
            def mask_frame(t):
                frame = np.zeros((text_clip_white.size[1], text_clip_white.size[0]), dtype=np.uint8)
                mask_width = int(text_clip_white.size[0] * progress)
                frame[:, :mask_width] = 255
                return frame

            mask_clip = VideoClip(make_frame=mask_frame, duration=duration).set_ismask(True)

            # Aplica a máscara ao clipe de texto amarelo
            text_clip_yellow = text_clip_yellow.set_mask(mask_clip)

            # Combina os clipes de texto branco e amarelo
            combined_clip = CompositeVideoClip([text_clip_white, text_clip_yellow])

            return combined_clip

        # Retorna o clipe de texto com a duração definida
        return color_transition(0).set_duration(duration)

    if subtitle_text:
        subtitles = SubtitlesClip(subtitle_file, lambda txt: create_subtitle_clip(txt, duration=audio_duration))
    else:
        subtitles = ImageClip("imagens/1pixel.png").set_duration(audio_duration)
        print("Arquivo de legenda inválido.")

    if not song or not artist:
        song_title = os.path.splitext(os.path.basename(audio_file))[0]
    else:
        song_title = f"{artist} - {song}"
        if key_shift:
            semitone_text = "semitom" if abs(key_shift) == 1 else "semitons"
            direction = "para cima" if key_shift > 0 else "para baixo"
            song_title += f" (transposto {key_shift} {semitone_text} {direction})"

    # Criar os títulos conforme solicitado
    playing_now = TextClip("Tocando agora:", fontsize=font_size_title_medium, color='white', font=font_arial, size=(int(size[0]//8), None), align='West').set_position(('left', 'top')).set_duration(audio_duration)
    artist_clip = TextClip(artist, fontsize=font_size_title_large, color='white', font=font_cooperblack, size=(int(size[0]//5), None), stroke_color='black', stroke_width=1, align='West').set_position(('left', playing_now.size[1])).set_duration(audio_duration)
    song_clip = TextClip(song, fontsize=font_size_title_large, color='white', font=font_cooperblack, size=(int(artist_clip.size[0]*1.5), None), stroke_color='black', stroke_width=1, align='West').set_position(('left', playing_now.size[1] + artist_clip.size[1])).set_duration(audio_duration)

    if key_shift:
        key_clip = TextClip(f"Tonalidade: {key_shift} semitons", fontsize=font_size_title_medium, color='white', font=font_cooperblack, size=(int(size[0]//6), None), align='West').set_position(('left', playing_now.size[1] + artist_clip.size[1] + song_clip.size[1])).set_duration(audio_duration)
        final_clip = CompositeVideoClip([spectrogram_clip, subtitles.set_position(subtitle_position), playing_now, artist_clip, song_clip, key_clip])
    else:
        final_clip = CompositeVideoClip([spectrogram_clip, subtitles.set_position(subtitle_position), playing_now, artist_clip, song_clip])

    final_clip = final_clip.set_audio(AudioFileClip(audio_file))
    final_clip.write_videofile(output_file, fps=fps, codec="libx264", audio_codec="aac")

def processatudo(entrada, key_shift, legenda, arqlegenda, artista, song, idioma='en', video4k='N', whispermodel=None, separador='demucs', ultrastar='N', video='S',):
    if avaliar_url_ou_arquivo(entrada) == 'url': 
        print(f'Passo 1: baixando música {artista} - {song} da url {entrada}')
    else: 
        print(f'Passo 1: Processando música {artista} - {song} do local {entrada}')
    
    if legenda == 'whisper' and whispermodel:
        arq_audio, arq_legenda, semitons, artista, musica = create_playback(entrada, pitch_shift=key_shift, legenda=legenda, idioma_legenda=idioma, artista=artista, musica=song, modelowhisper=whispermodel, separador=separador)
    else:
        arq_audio, arq_legenda, semitons, artista, musica = create_playback(entrada, pitch_shift=key_shift, legenda=legenda, artista=artista, musica=song, idioma_legenda=idioma, separador=separador)
        
    if video =='S':    
        if arqlegenda and legenda in ['nenhum', None]:
            print(f'Passo 2: gerando vídeo com a legenda fornecida {arqlegenda} para a música {artista} - {song}')
            create_karaoke_video(arq_audio, arqlegenda, f'video/oldtv/{artista} - {song} ({key_shift} tons) oldtv.mp4', artist=artista, song=song, key_shift=key_shift, resolution='oldtv', image_folder='imagens/oldtv')
            create_karaoke_video(arq_audio, arqlegenda, f'video/480p/{artista} - {song} ({key_shift} tons) 480p.mp4', artist=artista, song=song, key_shift=key_shift, resolution='480p', image_folder='imagens/480p') 
            create_karaoke_video(arq_audio, arqlegenda, f'video/fullhd/{artista} - {song} ({key_shift} tons) fullhd.mp4', artist=artista, song=song, key_shift=key_shift, image_folder='imagens/full_hd')
            create_karaoke_video(arq_audio, arqlegenda, f'video/vertical/{artista} - {song} ({key_shift} tons) vertical.mp4', artist=artista, song=song, key_shift=key_shift, resolution='vertical', image_folder='imagens/vertical')
            if video4k == 'S':
                print(f'Passo extra: gerando vídeo em 4K da música {artista} - {song}')
                create_karaoke_video(arq_audio, arqlegenda, f'video/4k/{artista} - {song} ({key_shift} tons) 4k.mp4', artist=artista, song=song, key_shift=key_shift, resolution='4k', image_folder='imagens/4k')
        elif legenda in ['whisper', 'yt_dlp', 'lyrics_ovh', 'whisper-api']:
            print(f'Passo 2: gerando vídeo com a legenda fornecida {arq_legenda} para a música {artista} - {song}')
            create_karaoke_video(arq_audio, arq_legenda, f'video/oldtv/{artista} - {song} ({key_shift} tons) oldtv.mp4', artist=artista, song=song, key_shift=key_shift, resolution='oldtv', image_folder='imagens/oldtv')
            create_karaoke_video(arq_audio, arq_legenda, f'video/480p/{artista} - {song} ({key_shift} tons) 480p.mp4', artist=artista, song=song, key_shift=key_shift, resolution='480p', image_folder='imagens/480p')
            create_karaoke_video(arq_audio, arq_legenda, f'video/fullhd/{artista} - {song} ({key_shift} tons) fullhd.mp4', artist=artista, song=song, key_shift=key_shift, image_folder='imagens/full_hd')
            create_karaoke_video(arq_audio, arq_legenda, f'video/vertical/{artista} - {song} ({key_shift} tons) vertical.mp4', artist=artista, song=song, key_shift=key_shift, resolution='vertical', image_folder='imagens/vertical')
            if video4k == 'S':
                print(f'Passo extra: gerando vídeo em 4K da música {artista} - {song}')
                create_karaoke_video(arq_audio, arq_legenda, f'video/4k/{artista} - {song} ({key_shift} tons) 4k.mp4', artist=artista, song=song, key_shift=key_shift, resolution='4k', image_folder='imagens/4k')
        else:
            print('Legenda não fornecida ou método de legenda inválido. Pulando a geração de vídeo.')

    if ultrastar == 'S':
        print(f'Passo extra: gerando dados para Karaoke UltraStar para a música {artista} - {song}')
        arq_original = f'audio/{artista} - {song} (original).mp3'
        saida_ultrastar = 'UltraStar'
        run_ultrasinger(arq_original, saida_ultrastar)

def gerarbackground(quantidade):
    if quantidade <= 0 or quantidade >= 30:
        raise ValueError("O valor de 'quantidade' deve ser um número inteiro positivo e menor que 30.")
    print(f'Baixando {quantidade} imagens de fundo para Full HD, 4K, vertical, 480p e oldtv...')
    baixar_imagens_paisagens(quantidade=quantidade, tamanho='full_hd')
    baixar_imagens_paisagens(quantidade=quantidade, tamanho='4k')
    baixar_imagens_paisagens(quantidade=quantidade, tamanho='vertical')
    baixar_imagens_paisagens(quantidade=quantidade, tamanho='480p')
    baixar_imagens_paisagens(quantidade=quantidade, tamanho='oldtv')
    
def gerarvideo(entrada, arqlegenda, artista, song, key_shift, ultrastar='N', video4k='N'):
    if avaliar_url_ou_arquivo(entrada) == 'url':
        raise ValueError("A opção 'gerarvideo' só aceita arquivos locais, não URLs.")
    
    print(f'Gerando vídeo com a legenda fornecida {arqlegenda} para a música {artista} - {song}')
    if video4k == 'N' or video4k == 'T':
        if not os.path.exists(f'video/oldtv/{artista} - {song} ({key_shift} tons) oldtv.mp4'):
            print(f'Gerando vídeo em oldtv para a música {artista} - {song}')
            create_karaoke_video(entrada, arqlegenda, f'video/oldtv/{artista} - {song} ({key_shift} tons) oldtv.mp4', artist=artista, song=song, key_shift=key_shift, resolution='oldtv', image_folder='imagens/oldtv')
        else:
            print(f'Vídeo em oldtv para a música {artista} - {song} já gerado. Pulando. Caso queira gerar novamente, exclua o arquivo gerado.')
        if not os.path.exists(f'video/480p/{artista} - {song} ({key_shift} tons) 480p.mp4'):
            print(f'Gerando vídeo em 480p para a música {artista} - {song}')
            create_karaoke_video(entrada, arqlegenda, f'video/480p/{artista} - {song} ({key_shift} tons) 480p.mp4', artist=artista, song=song, key_shift=key_shift, resolution='480p', image_folder='imagens/480p')        
        else:
            print(f'Vídeo em 480p para a música {artista} - {song} já gerado. Pulando. Caso queira gerar novamente, exclua o arquivo gerado.')        
        if not os.path.exists(f'video/fullhd/{artista} - {song} ({key_shift} tons).mp4'):
            print(f'Gerando vídeo em HD para a música {artista} - {song}')
            create_karaoke_video(entrada, arqlegenda, f'video/fullhd/{artista} - {song} ({key_shift} tons).mp4', artist=artista, song=song, key_shift=key_shift, image_folder='imagens/full_hd')
        else:
            print(f'Vídeo em HD para a música {artista} - {song} já gerado. Pulando. Caso queira gerar novamente, exclua o arquivo gerado.')
        if not os.path.exists(f'video/vertical/{artista} - {song} ({key_shift} tons) vertical.mp4'):            
            print(f'Gerando vídeo em HD vertical para a música {artista} - {song}')
            create_karaoke_video(entrada, arqlegenda, f'video/vertical/{artista} - {song} ({key_shift} tons) vertical.mp4', artist=artista, song=song, key_shift=key_shift, resolution='vertical', image_folder='imagens/vertical')
        else:
            print(f'Vídeo em HD vertical para a música {artista} - {song} já gerado. Pulando. Caso queira gerar novamente, exclua o arquivo gerado.')    
    if video4k == 'S' or video4k == 'T':
        if not os.path.exists(f'video/4k/{artista} - {song} ({key_shift} tons) 4k.mp4'):        
            print(f'Gerando vídeo em 4K para a música {artista} - {song}')
            create_karaoke_video(entrada, arqlegenda, f'video/4k/{artista} - {song} ({key_shift} tons) 4k.mp4', artist=artista, song=song, key_shift=key_shift, resolution='4k', image_folder='imagens/4k')
        else:
            print(f'Vídeo em 4k para a música {artista} - {song} já gerado. Pulando. Caso queira gerar novamente, exclua o arquivo gerado.')    
    if ultrastar == 'S':
        print(f'Gerando dados para Karaoke UltraStar para a música {artista} - {song}')
        saida_ultrastar = 'UltraStar'
        run_ultrasinger(entrada, saida_ultrastar)

def ajustarlegenda(arqlegenda, artista, song):
    resultado = replace_lyrics_in_srt(arqlegenda, artista, song)
    if resultado:
        print(f"Arquivo SRT atualizado: {resultado}")
    else:
        print("Não foi possível ajustar o arquivo SRT.")

def main():
    parser = argparse.ArgumentParser(description='Processa vídeos de karaokê a partir de uma URL ou arquivo local, ou baixa imagens de fundo.')

    # Opção para gerar background sozinha
    parser.add_argument('--gerarbackground', type=int, help='Gera imagens de fundo (inteiro entre 1 e 29).')

    # Opção para gerar vídeo com legenda fornecida (sem baixar)
    parser.add_argument('--gerarvideo', action='store_true', help='Gera um vídeo a partir de um arquivo local e legenda fornecida.')
    
    # Opção para ajustar legendas
    parser.add_argument('--ajustarlegenda', action='store_true', help='Ajusta legendas de um arquivo SRT com letras obtidas de lyrics.ovh.')

    # Argumentos para gerar vídeo
    parser.add_argument('-e', '--entrada', help='URL ou caminho local do vídeo')
    parser.add_argument('-k', '--key_shift', type=int, help='Valor do pitch shift (ajuste de semitons)')
    parser.add_argument('-l', '--legenda', choices=['whisper', 'yt_dlp', 'lyrics_ovh', 'whisper-api', 'nenhum'], 
                        help='Escolha o método de geração de legenda: whisper, yt_dlp, lyrics_ovh, whisper-api ou nenhum.')
    parser.add_argument('-a', '--artista', help='Nome do artista')
    parser.add_argument('-s', '--song', help='Nome da música')
    parser.add_argument('-i', '--idioma', default='en', help='Idioma da legenda (padrão: en)')
    parser.add_argument('-v4', '--video4k', default='N', choices=['S', 'N', 'T'], help='Gera vídeo em 4K (S - Somente 4K, N - Somente resoluções HD, T - Gerar resoluções HD e 4K)')
    parser.add_argument('-w', '--whispermodel', help='Modelo Whisper (só tem efeito se a opção de legenda for whisper)')
    parser.add_argument('-sep', '--separador', default='demucs', choices=['spleeter', 'demucs'], help='Escolha o algoritmo separador de áudio (padrão: demucs)')
    parser.add_argument('-ultra', '--ultrastar', default='N', choices=['S', 'N'], help='Gera arquivo UltraStar (S/N)')
    parser.add_argument('--arqlegenda', help='Arquivo de legenda no formato .srt para gerar o vídeo diretamente.')
    parser.add_argument('--video', default='S', choices=['S', 'N'], help='Gera o vídeo para a entrada usando a função padrão.')

    args = parser.parse_args()

    # Verifica se a opção gerarbackground foi fornecida e executa-a sozinha
    if args.gerarbackground:
        gerarbackground(args.gerarbackground)
    elif args.gerarvideo:
        if args.entrada and args.arqlegenda and args.artista and args.song and args.key_shift:
            gerarvideo(args.entrada, args.arqlegenda, args.artista, args.song, args.key_shift, args.ultrastar, args.video4k)
        else:
            parser.error("Argumentos insuficientes fornecidos para gerar o vídeo.")
    elif args.ajustarlegenda:
        if args.arqlegenda and args.artista and args.song:
            ajustarlegenda(args.arqlegenda, args.artista, args.song)
        else:
            parser.error("Argumentos insuficientes fornecidos para ajustar a legenda.")
    else:
        # Checa se os demais argumentos requeridos para processatudo foram fornecidos
        if args.entrada and args.key_shift and args.legenda and args.artista and args.song:
            if args.video == 'N':
                processatudo(args.entrada, args.key_shift, args.legenda, args.arqlegenda, args.artista, args.song, args.idioma, args.video4k, args.whispermodel, args.separador, args.ultrastar, args.video)
            elif args.video == 'S':
                processatudo(args.entrada, args.key_shift, args.legenda, args.arqlegenda, args.artista, args.song, args.idioma, args.video4k, args.whispermodel, args.separador, args.ultrastar)
            else:
                print("Isso não deveria aparecer")
        else:
            parser.error("Argumentos insuficientes fornecidos para o processamento de karaokê.")

if __name__ == "__main__":
    main()
